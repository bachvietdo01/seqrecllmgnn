model: SRGNNSEQLLM
item_embedding_size: 512
gnn_step: 2
seq_n_layers: 2
seq_n_heads: 4
seq_embedding_size: 512
seq_inner_size: 2
seq_hidden_dropout_prob: 0.1
seq_attn_dropout_prob: 0.1
seq_hidden_act: 'gelu'
seq_layer_norm_eps: 1e-12
seq_initializer_range: 0.02
llm_embed_dim: 4096
query_model: '/home/bachdo/meta-llama/Meta-Llama-3-8B-Instruct'
encoder_model: 'intfloat/e5-mistral-7b-instruct'
llm_gpu_utlization: 0.3
